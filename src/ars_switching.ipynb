{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sgillen/work/seagul/seagul/envs/__init__.py:57: UserWarning: Warning, pybullet envs not installed\n",
      "  warnings.warn(\"Warning, pybullet envs not installed\")\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import torch\n",
    "\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng()         \n",
    "\n",
    "import seagul.envs\n",
    "from seagul.nn import MLP\n",
    "from seagul.rl.ars import ARSAgent\n",
    "\n",
    "%matplotlib tk\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.7.4)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('tree_simple-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_net(net, channel=0):\n",
    "    x = np.linspace(0,10, 200)\n",
    "    y = np.linspace(-1,2,100)\n",
    "\n",
    "    C = np.zeros([x.shape[0], y.shape[0]])\n",
    "    \n",
    "    softmax = torch.nn.Softmax()\n",
    "\n",
    "    for i in range(C.shape[0]):\n",
    "        for j in range(C.shape[1]):\n",
    "            C[i,j] =  softmax(net(torch.tensor([x[i], y[j]], dtype=torch.float32)))[channel]\n",
    "\n",
    "    # %%\n",
    "    X,Y = np.meshgrid(x,y, indexing='ij')\n",
    "\n",
    "    fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "\n",
    "    ax.plot_surface(X,Y,C, facecolors=cm.Spectral(C/np.amax(C)), alpha=.5)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('C')\n",
    "\n",
    "\n",
    "def do_rollout_train(env, policy,seed=None):\n",
    "    state_list = []\n",
    "    act_list = []\n",
    "    reward_list = []\n",
    "\n",
    "    env.seed(seed)\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        state_list.append(np.copy(obs))\n",
    "        actions = policy(obs)\n",
    "#         actions,_,_,_ = policy.step(obs)\n",
    "        obs, reward, done, _ = env.step(actions)\n",
    "\n",
    "        act_list.append(np.array(actions))\n",
    "        reward_list.append(reward)\n",
    "\n",
    "\n",
    "    state_arr = np.stack(state_list)\n",
    "    act_arr = np.stack(act_list)\n",
    "    reward_sum = (np.sum(reward_list).item())\n",
    "\n",
    "    return state_arr, reward_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_size = env.observation_space.shape[0]\n",
    "act_size = env.action_space.shape[0]\n",
    "W1 = np.zeros((obs_size, act_size))\n",
    "W1[0] = 5\n",
    "W2 = np.zeros((obs_size, act_size))\n",
    "W2[0] = -5\n",
    "\n",
    "n_param = W1.size\n",
    "n_delta = 2048\n",
    "exp_noise = .025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = rng.standard_normal((n_delta, n_param))\n",
    "pm_W1 = np.concatenate((W1.flatten()+(deltas*exp_noise), W1.flatten()-(deltas*exp_noise)))\n",
    "R1 = []\n",
    "O1 = []\n",
    "\n",
    "seeds = rng.integers(2**32, size=(pm_W1.shape[0]))\n",
    "\n",
    "for i,Ws in enumerate(pm_W1):\n",
    "    seed = seeds[i]\n",
    "    policy = lambda x: Ws.T@x\n",
    "    o,R = do_rollout_train(env, policy, seed)\n",
    "    R1.append(R)\n",
    "    O1.append(o)\n",
    "    \n",
    "    \n",
    "\n",
    "deltas = rng.standard_normal((n_delta, n_param))\n",
    "pm_W2 = np.concatenate((W2.flatten()+(deltas*exp_noise), W2.flatten()-(deltas*exp_noise)))\n",
    "R2 = []\n",
    "O2 = []\n",
    "\n",
    "for i,Ws in enumerate(pm_W2):\n",
    "    seed = seeds[i]\n",
    "    policy = lambda x: Ws.T@x\n",
    "    o,R = do_rollout_train(env, policy, seed)\n",
    "    R2.append(R)\n",
    "    O2.append(o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = []\n",
    "Ytrain = []\n",
    "\n",
    "for i in range(len(seeds)):\n",
    "    r1 = R1[i]\n",
    "    r2 = R2[i] \n",
    "    \n",
    "    if r1 > r2:\n",
    "        [Xtrain.append(o) for o in O1[i]]\n",
    "        [Ytrain.append(1) for _ in O1[i]] \n",
    "        \n",
    "    else:\n",
    "        [Xtrain.append(o) for o in O2[i]]\n",
    "        [Ytrain.append(0) for _ in O2[i]] \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = np.array(Xtrain, np.float32)\n",
    "Ytrain = np.array(Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:07<00:00,  6.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1bb0a87f50>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from seagul.nn import fit_model\n",
    "classifier = MLP(env.observation_space.shape[0], 2, 2, 16)\n",
    "visualize_net(classifier)\n",
    "\n",
    "plt.title(\"Before\")\n",
    "loss_hist = fit_model(classifier, Xtrain, Ytrain, 50, batch_size=2048, loss_fn=torch.nn.CrossEntropyLoss())\n",
    "\n",
    "visualize_net(classifier)\n",
    "plt.title(\"After\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('input_bias', tensor([0., 0.])), ('output_layer.weight', tensor([[ 0.3092, -0.1770]])), ('output_layer.bias', tensor([-0.0574]))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.15it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.28it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.47it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.09it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.13it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.54it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.74it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.48it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.53it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.70it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.43it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.11it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.57it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.77it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.48it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.47it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.14it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.35it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.81it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.12it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.31it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.39it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.46it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.50it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.70it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.74it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.42it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.74it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.94it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.47it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.07it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.19it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.73it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.76it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.28it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.70it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.39it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.47it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.31it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.73it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.44it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.75it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.15it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.61it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.43it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.43it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.06it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.32it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.15it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('input_bias', tensor([0., 0.])), ('output_layer.weight', tensor([[ 0.3092, -0.1770]])), ('output_layer.bias', tensor([-0.0574]))])\n",
      "OrderedDict([('input_bias', tensor([0.0061, 0.0020], dtype=torch.float64)), ('output_layer.weight', tensor([[ 0.3569, -0.1665]], dtype=torch.float64)), ('output_layer.bias', tensor([-0.0455], dtype=torch.float64))])\n",
      "OrderedDict([('input_bias', tensor([0.0061, 0.0020], dtype=torch.float64)), ('output_layer.weight', tensor([[ 0.3569, -0.1665]], dtype=torch.float64)), ('output_layer.bias', tensor([-0.0455], dtype=torch.float64))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from seagul.nn import MLP\n",
    "import seagul.envs\n",
    "\n",
    "import gym\n",
    "import copy\n",
    "from seagul.rl.ars.ars_switching import ARSSwitchingAgent, ARSSwitchingModel\n",
    "from seagul.rl.ars.ars_torch import ARSTorchModel\n",
    "\n",
    "\n",
    "env = gym.make(\"tree_simple-v0\")\n",
    "\n",
    "policy = MLP(env.observation_space.shape[0], env.action_space.shape[0], 0, 0, input_bias=True)\n",
    "classifier = MLP(env.observation_space.shape[0], 2, 2, 16)\n",
    "\n",
    "model = ARSTorchModel(policy)\n",
    "model_list = [copy.deepcopy(model) for _ in range(2)]\n",
    "\n",
    "switching_agent = ARSSwitchingAgent('tree_simple-v0', model_list, classifier, n_delta=64, n_top=64)\n",
    "\n",
    "print(switching_agent.model_list[0].policy.state_dict())\n",
    "switching_agent.learn(50)\n",
    "print(switching_agent.model_list[0].policy.state_dict())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('input_bias', tensor([-0.0024,  0.0016], dtype=torch.float64)), ('output_layer.weight', tensor([[ 0.0278, -0.1380]], dtype=torch.float64)), ('output_layer.bias', tensor([0.3035], dtype=torch.float64))])\n",
      "OrderedDict([('input_bias', tensor([-0.0012,  0.0035], dtype=torch.float64)), ('output_layer.weight', tensor([[ 0.0255, -0.1274]], dtype=torch.float64)), ('output_layer.bias', tensor([0.3054], dtype=torch.float64))])\n"
     ]
    }
   ],
   "source": [
    "print(switching_agent.model_list[0].policy.state_dict())\n",
    "print(switching_agent.model_list[1].policy.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_net(switching_agent.classifier, channel=0)\n",
    "visualize_net(switching_agent.classifier, channel=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Base (3.7)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
